import ij.IJ;
import ij.ImagePlus;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.TreeMap;

import jitk.spline.ThinPlateR2LogRSplineKernelTransform;
import net.imglib2.RealRandomAccess;
import net.imglib2.RealRandomAccessible;
import net.imglib2.img.Img;
import net.imglib2.img.display.imagej.ImageJFunctions;
import net.imglib2.interpolation.randomaccess.NearestNeighborInterpolatorFactory;
import net.imglib2.realtransform.AffineGet;
import net.imglib2.realtransform.AffineTransform2D;
import net.imglib2.realtransform.AffineTransform3D;
import net.imglib2.realtransform.RealViews;
import net.imglib2.type.numeric.ARGBType;
import net.imglib2.type.numeric.NumericType;
import net.imglib2.type.numeric.RealType;
import net.imglib2.type.numeric.integer.UnsignedByteType;
import net.imglib2.type.numeric.integer.UnsignedShortType;
import net.imglib2.type.numeric.real.FloatType;
import net.imglib2.view.Views;

import org.json.JSONArray;
import org.json.JSONObject;

import fiji.util.gui.GenericDialogPlus;
import bigwarp.landmarks.LandmarkTableModel;
import au.com.bytecode.opencsv.CSVWriter;

 HashMap parseJSON( String jsonFilePath ) 
	{
		//jsonString = new String( Files.readAllBytes( Paths.get( jsonFilePath ) ), StandardCharsets.UTF_8 );
		//json = new JSONObject( jsonString );

        rd = new BufferedReader(new FileReader( jsonFilePath ));
		builder = new StringBuilder();
		inputLine = null;
		while((inputLine = rd.readLine()) != null)
			builder.append( inputLine );

		rd.close();

		json = new JSONObject( builder.toString() );

		map = new HashMap();
		add( json, map );
		return map;
	}
	
void add( JSONObject jsonObj, Map map )
	{
		if( jsonObj.has( "id" ) && jsonObj.has( "name" ))
		{
			map.put( jsonObj.getInt( "id" ), jsonObj.getString( "name" ) );
		}

		if( jsonObj.has( "children" ))
		{
			jsonArray = jsonObj.getJSONArray( "children" );
			for( int i = 0; i < jsonArray.length(); i++ )
				add( jsonArray.getJSONObject( i ), map );
		}
	}

String[] prepend( String pre, String[] post )
	{
		String [] out = new String[ post.length + 1 ];
		out[ 0 ] = pre;
		for( int i = 0; i < post.length; i++ )
			out[ i + 1 ] = post[ i ];
		
		return out;
	}

ArrayList createRows( 
			ArrayList values, 
			ArrayList pts,
			ArrayList ptsXfm,
			HashMap atlasOntology  )
	{
		i = 0;
		out = new ArrayList( values.size() );
		for( RealType v : values )
		{
			pt    = pts.get( i );
			ptxfm = ptsXfm.get( i );
			if( atlasOntology != null )
			{
				out.add( new String[]{ 
						Double.toString( pt[0]), Double.toString( pt[1]), Double.toString( pt[2]),
						Double.toString( ptxfm[0]), Double.toString( ptxfm[1]), Double.toString( ptxfm[2]),
						v.toString(),
						atlasOntology.get( (int) v.getRealDouble() )
						});
			}
			else
			{
				out.add( new String[]{ 
						Double.toString( pt[0]), Double.toString( pt[1]), Double.toString( pt[2]),
						Double.toString( ptxfm[0]), Double.toString( ptxfm[1]), Double.toString( ptxfm[2]),
						v.toString()
						});
			}
			
			i++;
		}
		return out;
	}


TreeMap getCountsPerLabel( ArrayList labelList )
    {
        countsByLabel = new TreeMap();
       
        for( Object l : labelList )
        {
            if( countsByLabel.containsKey( l ))
            {
                // increment the count for this label
                countsByLabel.put( l, countsByLabel.get( l ).intValue() + 1 );
            }
            else
            {
                countsByLabel.put( l, 1 );
            }
        }
        return countsByLabel;
    }

void writeToCSV( Map mapOut, File f ) 
	{
		allrows = new ArrayList(); 
		for( String key : mapOut.keySet() )
		{
			for( String[] v : mapOut.get( key ))
			{
				allrows.add( prepend( key, v ) );
			}
		}

		writer = new CSVWriter( new FileWriter( f ));
		writer.writeAll( allrows );
		writer.close();
	}

 void writeCountsToCSV( 
			TreeMap countMapOut,
			Map atlasOntology,
			File f )
	{
		allrows = new ArrayList();
		
		for( String key : countMapOut.keySet() )
		{
			map2 = countMapOut.get( key );
			for( RealType k2 : map2.keySet())
			{
				allrows.add( new String[]{ 
						key, 
						k2.toString(),
						atlasOntology.get( (int)k2.getRealDouble() ),
						map2.get( k2 ).toString() } );
			}
		}
		
		writer = new CSVWriter( new FileWriter( f ));
		writer.writeAll( allrows );
		writer.close();
	}

RealRandomAccessible interpImagePlus( ImagePlus ip )
{

    double rx = ip.getLocalCalibration().pixelWidth;
    double ry = ip.getLocalCalibration().pixelHeight;
    double rz = ip.getLocalCalibration().pixelDepth;
    
    AffineGet xfm;
    if( ip.getNSlices() <=1 )
    {
        AffineTransform2D tmp = new AffineTransform2D();
        tmp.set(   rx,  0.0, 0.0, 
                  0.0,   ry, 0.0 );
        xfm = tmp;
    }
    else
    {
        AffineTransform3D tmp = new AffineTransform3D();
        tmp.set(   rx,  0.0,  0.0, 0.0,
                  0.0,   ry,  0.0, 0.0,
                  0.0,  0.0,   rz, 0.0 );
        xfm = tmp;
    }
    
    switch ( ip.getType() )
    {
    case ImagePlus.GRAY8:
         return RealViews.affine( 
                    Views.interpolate( 
                         Views.extendZero( ImageJFunctions.wrap(  ip ) ), 
                         new NearestNeighborInterpolatorFactory() ), 
                 xfm );
    case ImagePlus.GRAY16:
         return RealViews.affine(  
                    Views.interpolate( 
                         Views.extendZero( ImageJFunctions.wrap(  ip ) ), 
                         new NearestNeighborInterpolatorFactory() ),
                 xfm );
    case ImagePlus.GRAY32:
        return RealViews.affine(  
                    Views.interpolate( 
                        Views.extendZero( ImageJFunctions.wrap(  ip ) ), 
                        new NearestNeighborInterpolatorFactory() ),
                 xfm );
    case ImagePlus.COLOR_RGB:
         return RealViews.affine(  
                    Views.interpolate( 
                            Views.extendZero( ImageJFunctions.wrap(  ip ) ), 
                            new NearestNeighborInterpolatorFactory() ),
                 xfm );
    }
    return null;

}

ArrayList getPointValues( RealRandomAccessible img, List pts )
{

    RealRandomAccess rrai = img.realRandomAccess();
    ArrayList out = new ArrayList( pts.size() );

    for( double[] thispt : pts )
    {
        rrai.setPosition( thispt );
        out.add( rrai.get().copy() );
    }

    return out;
}
	
ArrayList transformPoints( ArrayList pts, ThinPlateR2LogRSplineKernelTransform xfm, boolean inverse )
{
    out = new ArrayList( pts.size() );
    if( inverse )
	{
		for( double[] pt : pts )
	    {
		    warpedPt = xfm.initialGuessAtInverse( pt, 5.0 );
		    xfm.inverseTol( pt, warpedPt, 2.0, 4000 );
		    out.add( warpedPt );
		}
	}
	else
	{
		for( double[] pt : pts )
			out.add( xfm.apply( pt ));
	}
    
    return out;
}

double[] parseLine( String line, int dim, boolean transformToAscConvention, Double actualZ )
{
    String lineed = (line.substring( line.indexOf( '(' ) + 1, line.indexOf( ')' ) -1 )).trim();
    
    String[] nums = lineed.split( "\\s" );
    double[] out = new double[ dim ];
    int i = 0;
    for( String s : nums )
    {
            try
			{
				if( i == 2 )
				{
                    if( actualZ == null || !Double.isNaN( actualZ ))
                        out[ i++ ] = actualZ.doubleValue();
			        else	
                    {
                        double d = Double.parseDouble( s );
                        // SARADA!
                        // Change the line below to modify the convention used to convert from z-values 
                        out[ i++ ] = ( -d ) / 100;
                    }
				}
				else if( transformToAscConvention && i == 1 )
				{
                    /* only negate the value of z */
					double d = Double.parseDouble( s );
					out[ i++ ] = -d;
				}
				else
				{
					double d = Double.parseDouble( s );
					out[ i++ ] = d;
				}
				
			}catch( Exception e ) {}
			
			if( i == dim )
			{
				return out;
			}
    }
    
    return out;
}

TreeMap readPointsAllNames( String f, int dim, boolean transformToAscConvention, Double actualZ )
{
    BufferedReader br = null;
    TreeMap map = new TreeMap();

    int nameIndex = 0;

    try
    {
        br = new BufferedReader( new FileReader( f ));
         
         String line;
         boolean amReading = false;
         
         ArrayList ptList = null;
         String name = "";
         while ((line = br.readLine()) != null) 
         {
             
             // find the line to signal stop reading
             if( amReading && line.contains( "End of markers" ))
             {
                 amReading = false;
                 map.put( name, ptList );
                 nameIndex++;
                 continue;
             }

             // find the line to start reading from
             if( line.contains( "Name" ) )
             {
                 amReading = true;
                 ptList = new ArrayList();
                 
                 // parse name
                 int idx = line.indexOf( "Name" );
                 name = line.split( "\"" )[1];
                 name = nameIndex + "-" + name;
                 
                 continue;
             }
             
             if( !amReading )
                 continue;

            ptList.add( parseLine( line, dim, transformToAscConvention, actualZ ) );
         }
         
         br.close();
    }
    catch ( FileNotFoundException e )
    {
        e.printStackTrace();
    }
    catch ( IOException e )
    {
        e.printStackTrace();
    }
    
    return map;
}

public static ArrayList readPoints( String f, String name, int dim )
{
    BufferedReader br = null;
    ArrayList ptList = new ArrayList();

    try
    {
        br = new BufferedReader( new FileReader( f ));
         
         String line;
         boolean amReading = false;
         while ((line = br.readLine()) != null) 
         {

             // find the line to signal stop reading
             if( amReading && line.contains( "End of markers" ))
                 break;

             // find the line to start reading from
             if( line.contains( "Name" ) && line.contains( name ))
             {
                 amReading = true;
                 continue;
             }
             
             if( !amReading )
                 continue;

            ptList.add( parseLine( line, dim ) );
         }
         
         br.close();
    }
    catch ( FileNotFoundException e )
    {
        e.printStackTrace();
    }
    catch ( IOException e )
    {
        e.printStackTrace();
    }
    
    return ptList;
}

atlasOntologyFile = IJ.getDir("plugins") + "atlasStructureOntology.json";
atlasOntology = parseJSON( atlasOntologyFile );

basedefault = "";

imgf = basedefault;
ptsf = basedefault;
xfmf = basedefault;
fout = basedefault;

// dialog
gd = new GenericDialogPlus( "ASC files" );
gd.addChoice( "Number of dimensions", new String[]{"2","3"}, "3" );
gd.addNumericField("z value", Double.NaN, 4 );
gd.addFileField( "Template Image file", imgf );
gd.addFileField( "Landmarks: ", xfmf );
gd.addFileField( "Points ASC file: ", ptsf );
gd.addCheckbox( "inverse", false );
gd.showDialog();

if( gd.wasCanceled() )
{
    return null;
}

ndims  = gd.getNextChoiceIndex() + 2;
zValue = gd.getNextNumber();
imgf   = gd.getNextString();
xfmf   = gd.getNextString();
ptsf   = gd.getNextString();
inverse= gd.getNextBoolean();

// TODO: for testing
//imgf = "/data-ssd/john/forSarada/annotation_10.tif";
//xfmf = "/data-ssd/john/forSarada/Allan10_D10-051_refine_6.csv";
//ptsf = "/groups/saalfeld/public/sarada/051_from_30-39.ASC";

if( zValue == Double.NaN )
    zValue = null;

fout   = ptsf.replaceAll( ".ASC", "_pointLabels.csv" );
cfout  = ptsf.replaceAll( ".ASC", "_counts.csv" );

LandmarkTableModel ltm = new LandmarkTableModel( ndims );
ltm.load( new File( xfmf ));

xfm = ltm.getTransform();

ip = IJ.openImage( imgf );
ipInterp = interpImagePlus( ip );

/*
*  Transform the imageplus to conform to the ASC file conventions:
*  The origin is at the "top left" corner as usual, and y values *decrease* from top to bottom
*  For now, always do this and don't expose the option
*/
ptMap = readPointsAllNames( ptsf, ndims, true, zValue );
mapOut      = new TreeMap();
countMapOut = new TreeMap();

for( String key : ptMap.keySet() )
{
    keyPts = ptMap.get( key );
    ptsXfm = transformPoints( keyPts, xfm, !inverse );

    vals = getPointValues( ipInterp, ptsXfm );

    mapOut.put( key, createRows( vals, keyPts, ptsXfm, atlasOntology ));
    countMapOut.put( key, getCountsPerLabel( vals ));
}

writeToCSV( mapOut, new File( fout ));
writeCountsToCSV( countMapOut, atlasOntology, new File( cfout ));

IJ.showMessage("Point transform finished, results:\n" + 
    fout + "\n" + 
    cfout);
